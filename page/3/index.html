<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>NuSkool</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="NuSkool"><meta name="msapplication-TileImage" content="img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="NuSkool"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="데이터덕후 블로그입니다."><meta property="og:type" content="blog"><meta property="og:title" content="NuSkool"><meta property="og:url" content="https://nullskool.github.io/"><meta property="og:site_name" content="NuSkool"><meta property="og:description" content="데이터덕후 블로그입니다."><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://nullskool.github.io/img/og_image.png"><meta property="article:author" content="NullSKool"><meta property="article:tag" content="Deep Learning, XR, Music"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://NullSKool.github.io"},"headline":"NuSkool","image":["https://nullskool.github.io/img/og_image.png"],"author":{"@type":"Person","name":"NullSKool"},"publisher":{"@type":"Organization","name":"NuSkool","logo":{"@type":"ImageObject","url":"https://nullskool.github.io/img/logo.svg"}},"description":"데이터덕후 블로그입니다."}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=G-M6KHR911M6" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'G-M6KHR911M6');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/rss2.xml" title="NuSkool" type="application/rss+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="NuSkool" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-11-25T12:49:48.000Z" title="2020. 11. 25. 오후 9:49:48">2020-11-25</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:20:00.187Z" title="2022. 4. 5. 오후 3:20:00">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a></span><span class="level-item">5분안에 읽기 (약 796 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/11/25/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%845/">딥러닝-입문과-준비5</a></h1><div class="content"><h2 id="딥러닝-시작해보기-5"><a href="#딥러닝-시작해보기-5" class="headerlink" title="딥러닝 시작해보기-5"></a>딥러닝 시작해보기-5</h2><h3 id="선형대수-배워보기-행렬을-아무리-곱하고-더해도-선모양"><a href="#선형대수-배워보기-행렬을-아무리-곱하고-더해도-선모양" class="headerlink" title="선형대수 배워보기(행렬을 아무리 곱하고 더해도 선모양)"></a>선형대수 배워보기(행렬을 아무리 곱하고 더해도 선모양)</h3><h4 id="Scala-크기만-존재하는-양"><a href="#Scala-크기만-존재하는-양" class="headerlink" title="Scala : 크기만 존재하는 양"></a>Scala : 크기만 존재하는 양</h4><h4 id="Vector-속도-위치이동-힘-공간뒤틀림과-같이-크기와-방향이-모두-존재하는-양"><a href="#Vector-속도-위치이동-힘-공간뒤틀림과-같이-크기와-방향이-모두-존재하는-양" class="headerlink" title="Vector : 속도, 위치이동, 힘, 공간뒤틀림과 같이 크기와 방향이 모두 존재하는 양"></a>Vector : 속도, 위치이동, 힘, 공간뒤틀림과 같이 크기와 방향이 모두 존재하는 양</h4><p><img src="/2020/11/25/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%845/slido51_1.PNG" alt="스칼라와벡터"></p>
<h4 id="Norm-n차원-벡터-vec-x-x3D-x-1-x-2-cdots-x-n"><a href="#Norm-n차원-벡터-vec-x-x3D-x-1-x-2-cdots-x-n" class="headerlink" title="Norm ? n차원 벡터 $$\vec{x} &#x3D; (x_1, x_2, \cdots x_n)$$"></a>Norm ? n차원 벡터 $$\vec{x} &#x3D; (x_1, x_2, \cdots x_n)$$</h4><p>Norm $$\lVert x \rVert &#x3D; \sqrt{x_1^1 + x_2^2 + \cdots + x_n^2}$$</p>
<blockquote>
<p>“원점 O에서 점\(x_1, x_2, \cdots, x_n\) 까지의 거리”</p>
</blockquote>
<h4 id="내적-Inner-product-Dot-product"><a href="#내적-Inner-product-Dot-product" class="headerlink" title="내적 ?  Inner product, Dot product"></a>내적 ?  Inner product, Dot product</h4><h4 id="행렬끼리-곱할-때는-차원을-주의한다"><a href="#행렬끼리-곱할-때는-차원을-주의한다" class="headerlink" title="행렬끼리 곱할 때는 차원을 주의한다."></a>행렬끼리 곱할 때는 차원을 주의한다.</h4><blockquote>
<p>A(m, n) * B(n, m) 만 가능</p>
</blockquote>
<h4 id="Transpose-전치행렬-행과-열을-뒤바꿈"><a href="#Transpose-전치행렬-행과-열을-뒤바꿈" class="headerlink" title="Transpose: 전치행렬(행과 열을 뒤바꿈)"></a>Transpose: 전치행렬(행과 열을 뒤바꿈)</h4><blockquote>
<p>A.T</p>
</blockquote>
<h3 id="numpy-연산-Element-wise-operation"><a href="#numpy-연산-Element-wise-operation" class="headerlink" title="numpy 연산(Element-wise operation)"></a>numpy 연산(Element-wise operation)</h3><blockquote>
<p>np.dot(x, y) (aka 내적, dot-product)와  x * y(element-wise)는 서로 다름.</p>
</blockquote>
<h3 id="numpy-비교-논리연산-element-wise-operation"><a href="#numpy-비교-논리연산-element-wise-operation" class="headerlink" title="numpy 비교, 논리연산(element-wise operation)"></a>numpy 비교, 논리연산(element-wise operation)</h3><h3 id="numpy-Reductions"><a href="#numpy-Reductions" class="headerlink" title="numpy Reductions"></a>numpy Reductions</h3><blockquote>
<p>argmax() : 최대값있는 인덱스를 리턴, argmin() : 최소값의 인덱스 리턴</p>
</blockquote>
<h3 id="np-all-np-any"><a href="#np-all-np-any" class="headerlink" title="np.all, np.any?"></a>np.all, np.any?</h3><blockquote>
<p>ALL : Array내 모든 값이 TRUE인가?<br>  any : Array내 값이 하나라도 TRUE인가?</p>
</blockquote>
<h3 id="np-mean-np-median-np-std-등-통계함수-사용-가능"><a href="#np-mean-np-median-np-std-등-통계함수-사용-가능" class="headerlink" title="np.mean, np.median, np.std 등 통계함수 사용 가능"></a>np.mean, np.median, np.std 등 통계함수 사용 가능</h3><h4 id="딥러닝에-대한-환상"><a href="#딥러닝에-대한-환상" class="headerlink" title="딥러닝에 대한 환상"></a>딥러닝에 대한 환상</h4><ol>
<li><p>복잡한 문제도 층을 깊고 넓게 쌓으면 해결된다 –&gt; Gradient Vanhshing, Initialize fault 으하하핰ㅋㅋㅋ</p>
</li>
<li><p>$$Sigmoid(z) &#x3D; \frac{1} {1 + e^{-z}}$$<br>  Sigmoid 도함수의 최대값은 1&#x2F;4 … –&gt; 그래서 Gradient Vanishing 나는거임 ㅇㅇ</p>
</li>
</ol>
<h4 id="가중치-초기화"><a href="#가중치-초기화" class="headerlink" title="가중치 초기화"></a>가중치 초기화</h4><ol>
<li><p>초기화의 중요성<br>  $$t &#x3D; wx+b$$ 에서 w가 100, b가 50이라면 x가 0.01이더라도 t는 51이 됨<br>  역전파때 sigmoid 함수 통과시키면 \(\sigma’ (51)\) 리턴됨<br>  하지만 t가 5만 넘어도 \(\sigma (t)\) 는 0에 수렴 –&gt; 이것이 바로 Gradient Vanishing…</p>
</li>
<li><p>그래서 입력층의 가중치w를 모두 0으로 리셋!<br>  Forward Propagation때 두번째 층 뉴런에 모두 같은 값이 전달됨<br>  Backward Propagation때 두째 층 가중치가 모두 똑같이 업데이트 &#x3D;&#x3D;&gt; 신경망 표현력 제한</p>
</li>
<li><p>Bias는 0으로 초기화하는게 일반적으로 효율적</p>
</li>
</ol>
<h4 id="가중치-초기화-2"><a href="#가중치-초기화-2" class="headerlink" title="가중치 초기화 2"></a>가중치 초기화 2</h4><ol>
<li><p>표준 정규분포를 이용한 가중치 초기화<br>  Sigmoid함수의 출력값이 극단적으로(0 or 1)에 치우치는 현상 –&gt; Gradient Vanishing</p>
</li>
<li><p>표준편차를 0.01로 하는 정규분포로 초기화<br>  가중치가 모여 있음 &#x3D;&gt; 기울기 소실 문제 어느정도 완화됨</p>
</li>
</ol>
<h4 id="가중치-초기화-3"><a href="#가중치-초기화-3" class="headerlink" title="가중치 초기화 3"></a>가중치 초기화 3</h4><p>  Xavier초기화 방법(2010)<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w = np.random.randn(n_input, n_output) / (n_input) ** <span class="number">0.5</span></span><br></pre></td></tr></table></figure><br>  Sigmoid와 같은 S자 함수의 경우 출력값들이 정규분포 형태이어야 안정적 학습 가능  </p>
<ul>
<li><p>Sigmoid function과 Xavier Init방법을 사용했을 경우 그래프<br>  <img src="/2020/11/25/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%845/ckpt_01.PNG" alt="sigmodi"></p>
</li>
<li><p>ReLU 계열 함수에는 적절하지 않음<br>layer를 거쳐갈 수록 0에 수렴(converge)</p>
<p><img src="/2020/11/25/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%845/ckpt_02.PNG" alt="reluNo"></p>
</li>
</ul>
<h4 id="가중치-초기화-4"><a href="#가중치-초기화-4" class="headerlink" title="가중치 초기화 4"></a>가중치 초기화 4</h4><p>  He 초기화 방법(2015)<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w = np.random.randn(n_input, n_output) / (n_input / <span class="number">2</span>) ** <span class="number">0.5</span></span><br></pre></td></tr></table></figure></p>
<p>  RELU + He init –&gt; 10 layer를 거쳐도 표준편차가 0으로 수렴하지 않음<br>  <img src="/2020/11/25/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%845/ckpt_03.PNG" alt="relu"></p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><ul>
<li>가중치 초기화는 너무나 중요함</li>
<li>tanh의 경우 Xavier Init 방법이 효율적</li>
<li>ReLU계열 함수에는 He Init 방법이 효율적</li>
<li>최근엔 대부분 He Init를 주로 사용</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-11-24T13:24:21.000Z" title="2020. 11. 24. 오후 10:24:21">2020-11-24</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:19:47.981Z" title="2022. 4. 5. 오후 3:19:47">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a></span><span class="level-item">4분안에 읽기 (약 591 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/">딥러닝-입문과-준비4</a></h1><div class="content"><h2 id="딥러닝-시작해보기-4"><a href="#딥러닝-시작해보기-4" class="headerlink" title="딥러닝 시작해보기-4"></a>딥러닝 시작해보기-4</h2><h3 id="인공신경망과-손실함수"><a href="#인공신경망과-손실함수" class="headerlink" title="인공신경망과 손실함수"></a>인공신경망과 손실함수</h3><ol>
<li>인공신경망의 기본 구조</li>
</ol>
<ul>
<li>뇌의 학습방법을 수학적으로 모델링한 기계학습 알고리즘</li>
<li>기본 구조 : y &#x3D; Wx+b<br> <img src="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/Letitgo_1.PNG" alt="인공신경망"><br> \(x_i\) : 입력, \(w_i\): 가중치, b : bias, f: 활성화함수<br> u : 결합(Net), z: 출력</li>
<li>뉴런에는 선형 결합과 활성화 함수 기능이 들어있음</li>
<li>입력층, 은닉층, 출력층으로 구성됨</li>
<li>각 노드의 뉴런 출력은 직접 전달되는 정보에만 의존할 뿐 다른 노드와는 무관</li>
<li>그래서? 병렬처리가 가능함.</li>
</ul>
<ol start="2">
<li>손실 함수(Loss or Cost function)</li>
</ol>
<ul>
<li>신경망의 출력값과 실제 결과값의 차이를 정의하는 함수</li>
<li>신경망 학습목표는 손실함수를 최소화 하는 방향으로 움직여야 함</li>
<li>SGD, Adam 등의 학습 최적화 알고리즘</li>
</ul>
<ol start="3">
<li>손실 함수</li>
</ol>
<ul>
<li><p>회귀(Regression)<br> 제곱 오차(MSE) 사용, 최근에는 rmse, mae의 장점이 있는 Huber Loss 사용하는 추세<br><img src="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/Letitgo_4.PNG" alt="회귀"></p>
</li>
<li><p>Huber Loss?<br>MAE + MSE -&gt; for Time Series Data!!<br><img src="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/Letitgo_5.PNG" alt="huber"><br><img src="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/Letitgo_7.PNG" alt="huber Loss"></p>
</li>
<li><p>분류(Classification)<br> 활성화 함수 : softmax, 손실함수 : cross-entropy<br><img src="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/Letitgo_2.PNG" alt="분류"></p>
</li>
</ul>
<h3 id="알고리즘과-역전파"><a href="#알고리즘과-역전파" class="headerlink" title="알고리즘과 역전파"></a>알고리즘과 역전파</h3><ol>
<li>학습 알고리즘</li>
</ol>
<ul>
<li>경사 하강법: 기울기를 이용하여 손실함수 S(\(\theta\)) 값을 최적화</li>
<li>gradient(기울기)의 반대 방향으로 일정 크기만큼 이동하는 것을 반복하여<br> 손실함수의 값을 최소화하는 \(\theta\)의 값을 찾음</li>
<li>\[\theta &#x3D; \theta - \eta \nabla_\theta S(\theta)\]</li>
<li>이 떄 \(eta\) 는 미리 정해진 learning rate(step size) 이고 보통 1e-3 ~ 1e-4 정도를 사용</li>
</ul>
<ol start="2">
<li>역전파</li>
</ol>
<ul>
<li><p>계산 그래프</p>
</li>
<li><p>노드는 연산을, 엣지는 데이터의 흐름방향<br> <img src="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/Letitgo_8.PNG" alt="Chain Rule"></p>
</li>
<li><p>sigmoid 함수 역전파<br> <img src="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/Letitgo_9.PNG" alt="sigmoidBP"></p>
</li>
<li><p>합성함수 미분법(Chain Rule)<br> <img src="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/Letitgo_10.PNG" alt="합성미분"></p>
</li>
<li><p>행렬연산과 역전파 1<br> <img src="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/Letitgo_11.PNG" alt="행렬역전파"></p>
</li>
<li><p>이진분류 2-layer NN 역전파<br> <img src="/2020/11/24/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%844/Letitgo_12.PNG" alt="이진역전파"></p>
</li>
</ul>
<blockquote>
<p>to be continued…</p>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-11-22T19:44:55.000Z" title="2020. 11. 23. 오전 4:44:55">2020-11-23</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:19:36.732Z" title="2022. 4. 5. 오후 3:19:36">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a></span><span class="level-item">몇 초안에 읽기 (약 111 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/11/23/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%843/">딥러닝-입문과-준비3</a></h1><div class="content"><h2 id="딥러닝-시작해보기-3"><a href="#딥러닝-시작해보기-3" class="headerlink" title="딥러닝 시작해보기-3"></a>딥러닝 시작해보기-3</h2><h3 id="차원수-늘리기-줄이기-TF2-x"><a href="#차원수-늘리기-줄이기-TF2-x" class="headerlink" title="차원수 늘리기, 줄이기(TF2.x)"></a>차원수 늘리기, 줄이기(TF2.x)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = tf.expand_dims(x, <span class="number">1</span>)</span><br><span class="line">x.shape <span class="comment"># (x.shape, 1)</span></span><br><span class="line"></span><br><span class="line">x[..., tf.newaxis].shape <span class="comment"># (x.shape, 1)</span></span><br><span class="line"></span><br><span class="line">np.squeeze(x[<span class="number">0</span>]).shape <span class="comment"># x.shape 차원 줄이기</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="TF2-x-Layers"><a href="#TF2-x-Layers" class="headerlink" title="TF2.x Layers"></a>TF2.x Layers</h3><p>Convolution</p>
<ul>
<li>filters : layer에서 출력될때 몇개의 filter</li>
<li>kernel_size : filter(weight) 의 사이즈</li>
<li>strides : 몇 개의 pixel만큼 skip하면서 sliding window 할 것인지</li>
<li>padding : same, zero</li>
<li>activation : 활성화 함수(<em>Linear function은 층을 쌓는 의미가 없다</em>)</li>
</ul>
<blockquote>
<p>to be Continued…</p>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-11-22T10:56:34.000Z" title="2020. 11. 22. 오후 7:56:34">2020-11-22</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:22:06.987Z" title="2022. 4. 5. 오후 3:22:06">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a></span><span class="level-item">1분안에 읽기 (약 145 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/11/22/TF2/">TF2</a></h1><div class="content"><h2 id="Tensorflow-2-x-사용법"><a href="#Tensorflow-2-x-사용법" class="headerlink" title="Tensorflow 2.x 사용법"></a>Tensorflow 2.x 사용법</h2><h3 id="Tensor-생성"><a href="#Tensor-생성" class="headerlink" title="Tensor 생성"></a>Tensor 생성</h3><ul>
<li><p>tf.constant() : list, tuple, Array 를 Tensor로 바꿈</p>
</li>
<li><p>tensor &#x3D; tf.constant(arr)</p>
</li>
<li><p>tensor.dtype : 데이터 타입 확인</p>
</li>
<li><p>tf.cast(tensor, dtype&#x3D;tf.uint8) : TF int8로 데이터타입 바꾸기<br> <img src="/2020/11/22/TF2/lect_2.PNG" alt="cast사용법"></p>
</li>
<li><p>tensor.numpy() : numpy array로 바꾸기</p>
</li>
</ul>
<h3 id="Tensor에-랜덤한-숫자들-생성"><a href="#Tensor에-랜덤한-숫자들-생성" class="headerlink" title="Tensor에 랜덤한 숫자들 생성"></a>Tensor에 랜덤한 숫자들 생성</h3><ul>
<li>numpy에서는 기본적인 normal distribution 생성<br> np.random.randn(9) : 9개의 불연속적이며 일정한 분포 난수 생성</li>
</ul>
<p>Distribution에 따른 난수 생성</p>
<ul>
<li><p>tf.random.normal<br> 중심극한 이론에 의한 연속적인 모양</p>
</li>
<li><p>tf.random.uniform<br> 불연속적이며 일정한 분포</p>
</li>
</ul>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-11-22T10:44:36.000Z" title="2020. 11. 22. 오후 7:44:36">2020-11-22</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:19:34.439Z" title="2022. 4. 5. 오후 3:19:34">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a></span><span class="level-item">1분안에 읽기 (약 117 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/11/22/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%842/">딥러닝 입문과 준비2</a></h1><div class="content"><h2 id="딥러닝-시작해보기-2"><a href="#딥러닝-시작해보기-2" class="headerlink" title="딥러닝 시작해보기-2"></a>딥러닝 시작해보기-2</h2><h3 id="Broadcast"><a href="#Broadcast" class="headerlink" title="Broadcast"></a>Broadcast</h3><p>두개의 행렬 shape가 서로 달라도<br>한쪽의 차원이 같거나, 연산하는 값이 한 개일때<br>shape에 맞게 복사해서 연산함</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">arr = np.arange(<span class="number">6</span>).reshape(-<span class="number">1</span>, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># [[0, 1, 2], </span></span><br><span class="line"><span class="comment">#  [3, 4, 5]]</span></span><br><span class="line"></span><br><span class="line">arr + <span class="number">3</span></span><br><span class="line"><span class="comment"># [[3, 4, 5],</span></span><br><span class="line"><span class="comment">#  [6, 7, 8]]</span></span><br><span class="line"></span><br><span class="line">arr * <span class="number">3</span></span><br><span class="line"><span class="comment"># [[0, 3, 6],</span></span><br><span class="line"><span class="comment">#  [9, 12 15]</span></span><br><span class="line"></span><br><span class="line">arr + np.array([<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># [[1, 3, 5],</span></span><br><span class="line"><span class="comment">#  [4, 6, 8]]</span></span><br><span class="line"></span><br><span class="line">np.add(arr, <span class="number">1</span>)</span><br><span class="line"><span class="comment"># 모든 원소에 1을 더함</span></span><br><span class="line"></span><br><span class="line">np.multiply(arr, <span class="number">3</span>)</span><br><span class="line"><span class="comment"># 모든 원소에 3을 곱함</span></span><br></pre></td></tr></table></figure>

<h3 id="argmax-argmin"><a href="#argmax-argmin" class="headerlink" title="argmax, argmin"></a>argmax, argmin</h3><p> 배열의 큰 값이나 작은 값의 index return<br> <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">arr = np.array([<span class="number">1</span>, <span class="number">4</span>, <span class="number">6</span>, <span class="number">54</span>, <span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line">np.argmax(arr) <span class="comment"># 54</span></span><br><span class="line">np.argmin(arr) <span class="comment"># 1</span></span><br><span class="line">np.unique(arr) <span class="comment"># 유일한 값 출력</span></span><br></pre></td></tr></table></figure></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-11-22T09:45:13.000Z" title="2020. 11. 22. 오후 6:45:13">2020-11-22</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:19:24.272Z" title="2022. 4. 5. 오후 3:19:24">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a></span><span class="level-item">2분안에 읽기 (약 362 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/11/22/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%84/">딥러닝 입문과 준비</a></h1><div class="content"><h2 id="딥러닝-시작해보기"><a href="#딥러닝-시작해보기" class="headerlink" title="딥러닝 시작해보기"></a>딥러닝 시작해보기</h2><h3 id="Tensor-이해하기"><a href="#Tensor-이해하기" class="headerlink" title="Tensor 이해하기"></a>Tensor 이해하기</h3><ol>
<li>차원</li>
</ol>
<ul>
<li>0차원(상수) : Scalar값</li>
<li>1차원(리스트 씌운 상수), 2차원(2d), 3차원(3d), 4차원(4-d), n차원(n-d) : Tensor</li>
<li>Numpy로 Tensor 표현과 응용이 가능</li>
</ul>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">arr = np.array([[<span class="number">3</span>, <span class="number">6</span>, <span class="number">9</span>], [<span class="number">2</span>, <span class="number">4</span>, <span class="number">8</span>]])</span><br><span class="line"><span class="built_in">print</span>(arr.dtype) <span class="comment"># dtype(&#x27;float64&#x27;)</span></span><br><span class="line"><span class="built_in">print</span>(arr.shape) <span class="comment"># (2, 3)</span></span><br><span class="line"><span class="built_in">print</span>(arr.size) <span class="comment"># 2 * 3 = 6</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<ol start="2">
<li>차원 늘리기와 줄이기</li>
</ol>
<ul>
<li><p>reshape, -1 활용</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arr.reshape(-<span class="number">1</span>) <span class="comment"># 1차원으로 펼치기</span></span><br><span class="line">arr.reshape(-<span class="number">1</span>, <span class="number">3</span>) <span class="comment"># 첫번째 차원은 알아서, 두번째 차원은 shape 3</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
</li>
<li><p>Ravel() : arr의 차원을 1로 바꿈(&#x3D;&#x3D;&gt; Flatten)</p>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">arr = np.array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], [<span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]]) <span class="comment"># (2, 3)</span></span><br><span class="line">arr.ravel()</span><br><span class="line">arr.shape <span class="comment">#(6, )</span></span><br></pre></td></tr></table></figure>
</li>
<li><p>np.expand_dims() : 값을 유지하고 차원만 늘릴때</p>
</li>
</ul>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">arr = np.expand_dims(arr, -<span class="number">1</span>) <span class="comment">#(6, 1)</span></span><br><span class="line">arr.shape</span><br></pre></td></tr></table></figure>

<ul>
<li>numpy array를 빠르게 채우는 방법!</li>
</ul>
 <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 0으로 채우기</span></span><br><span class="line">arr2 = np.zeros([<span class="number">3</span>, <span class="number">4</span>]) <span class="comment"># 3 * 4의 0이 채워진 배열</span></span><br><span class="line">one2 = np.ones([<span class="number">3</span>, <span class="number">4</span>]) <span class="comment"># 3 * 4의 1로 채워진 배열</span></span><br><span class="line"></span><br><span class="line">five2 = np.ones([<span class="number">3</span>, <span class="number">4</span>]) * <span class="number">5</span> <span class="comment"># 1로 채운 값에 5를 다 곱함</span></span><br><span class="line">arr2 = np.arange(n, m) <span class="comment"># n ~ m-1까지의  수로 배열 채우기</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># array([n ~ m-1])</span></span><br><span class="line">arr = np.arange(<span class="number">5</span>, <span class="number">11</span>).reshape(<span class="number">2</span>, -<span class="number">1</span>) </span><br><span class="line"><span class="comment"># 5 ~ 10 : 6개의 숫자, (2, 3)</span></span><br><span class="line"></span><br><span class="line">arr <span class="comment"># array([5, 6, 7]</span></span><br><span class="line">    <span class="comment">#       [8, 9, 10])</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<ul>
<li>모양이 맞지 않으면 Error…<br> 5, 6, 7, 8, 9는 5개의 숫자<br> 5 * 1 만 가능한.<br> <img src="/2020/11/22/%EB%94%A5%EB%9F%AC%EB%8B%9D-%EC%9E%85%EB%AC%B8%EA%B3%BC-%EC%A4%80%EB%B9%84/slide_lect.PNG" alt="모양다름"></li>
</ul>
<ol start="3">
<li>Index &amp; slicing</li>
</ol>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 리스트 인덱스 &amp; 슬라이싱</span></span><br><span class="line"></span><br><span class="line">nums = [<span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>]</span><br><span class="line">nums[:-<span class="number">1</span>] <span class="comment"># 마지막 숫자 전까지 표시</span></span><br><span class="line"></span><br><span class="line">nums[::-<span class="number">1</span>] <span class="comment"># 리스트 안의 숫자를 거꾸로 표현</span></span><br><span class="line"></span><br><span class="line">nums = [[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], <span class="number">4</span>, <span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>]</span><br><span class="line"><span class="built_in">print</span>(nums[<span class="number">0</span>][<span class="number">1</span>]) = <span class="number">2</span> <span class="comment"># 첫번째 리스트 안의 인덱스가 1인 숫자</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">arr = np.array([<span class="number">5</span>, <span class="number">6</span>, <span class="number">7</span>], [<span class="number">8</span>, <span class="number">9</span>, <span class="number">10</span>])</span><br><span class="line"><span class="built_in">print</span>(arr[<span class="number">1</span>, <span class="number">2</span>]) <span class="comment"># 10 --&gt; 인덱싱 [행, 열]</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(arr[<span class="number">1</span>:, <span class="number">1</span>:]) <span class="comment"># [[9, 10]]</span></span><br></pre></td></tr></table></figure>

<ol start="4">
<li>Boolean Indexing<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = np.random.randn(<span class="number">3</span>, <span class="number">3</span>)</span><br><span class="line"><span class="built_in">print</span>(data&lt;=<span class="number">0</span>) <span class="comment"># False, True로 나옴</span></span><br><span class="line"></span><br><span class="line">data[data &lt;=<span class="number">0</span>] = <span class="number">1</span> <span class="comment"># 0 이하인 것을 1로 채우다</span></span><br></pre></td></tr></table></figure></li>
</ol>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-11-17T12:28:07.000Z" title="2020. 11. 17. 오후 9:28:07">2020-11-17</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:21:52.227Z" title="2022. 4. 5. 오후 3:21:52">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a></span><span class="level-item">5분안에 읽기 (약 687 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/11/17/GAN%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-try/">GAN프로젝트_try</a></h1><div class="content"><h2 id="Style-GAN-toy-프로젝트"><a href="#Style-GAN-toy-프로젝트" class="headerlink" title="Style GAN toy 프로젝트"></a>Style GAN toy 프로젝트</h2><h3 id="StyleGAN의-특징"><a href="#StyleGAN의-특징" class="headerlink" title="StyleGAN의 특징"></a>StyleGAN의 특징</h3><ol>
<li>이미지를 Style의 조합으로 보고<br>Generator의 각 Layer마다 Style 정보를 입히는 방식으로 이미지 합성<br>이 때 각 Layer에서 추가되는 Style은 이미지의 Coarse Feature(포즈, 성별 등)부터<br>Fine Detail(머리색, 피부톤 등)까지<br>각기 다른 Level의 Visual 속성들을 조절 가능<br>StyleGAN은 생각보다 안정적이고 높은 퀄리티의 이미지 생성</li>
</ol>
<h3 id="네트워크-구조-Module"><a href="#네트워크-구조-Module" class="headerlink" title="네트워크 구조(Module)"></a>네트워크 구조(Module)</h3><ol>
<li>GAN이란 어떤 것일까???<br><img src="/2020/11/17/GAN%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-try/GANdesc.png" alt="이것이 GAN"></li>
</ol>
<p><img src="/2020/11/17/GAN%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-try/slide21.PNG" alt="GAN model"></p>
<ul>
<li>Instance Norm?<br><img src="/2020/11/17/GAN%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-try/slide22.PNG" alt="Instance Norm"></li>
</ul>
<p><img src="/2020/11/17/GAN%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-try/slide23.PNG" alt="Instance Norm2"></p>
<ul>
<li>Generator 구조 설명</li>
</ul>
<p><img src="/2020/11/17/GAN%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-try/slide322.png" alt="model"></p>
<p>왼쪽이 Traditional Network, 오른쪽이 이 논문에서 제안한 Style-gased Generator. </p>
<p>왼쪽 네트워크와 오른쪽에 Synthesis Network가 똑같은 구조를 갖고 있지만,<br>이전 GAN에서는 Latent z를 바로 Input으로 넣어줬던 것과는 다르게,<br>StyleGAN에서는 학습된 Constant, (w) 값을 입력으로 사용함. </p>
<p>새롭게 Mapping Network와 Noise가 추가됨..</p>
<p>W를 Feature에 매핑하는 경우<br>W는 Z처럼 고정된 분포를 따르지 않음. </p>
<p>Sampling density는 학습된 Piecewise Continuous Mapping f(z)<br>(f는 Mapping Network 입니다)에 의해 정해짐. </p>
<p>따라서, Warping(틀어짐)이 많이 일어나지 않음.<br>그렇기 때문에 Factors of variation은 더욱 Linear하고, Disentangled (얽히지 않음).<br>이것이 바로 z를 곧바로 Feature에 매핑하는 것보다 w에 매핑하는 것의 장점입니다</p>
<p>기존의 Generator (a)는<br>Input Latent Vector (z)가 직접 Convolution, Upsampling 등을 거쳐 이미지로 변환되는 구조. </p>
<p>Style-based Generator (b) 의 경우,<br>(z)가  Fully-connected Layer로 구성된 Mapping Network을 거쳐<br>Intermediate Latent Vector (w) 먼저 변환. </p>
<p>(w)는 Constant Tensor가 이미지로 변환되는 과정에서<br>스타일을 입히는 역할을 수행.</p>
<p>다양한 스타일의 이미지를 생성.</p>
<ul>
<li>Style Transfer를 실시간으로 가능케하는 Adaptive Instance Norm</li>
</ul>
<p>Synthesis Network (합성 네트워크)<br>z를 중간 latent space W에 매핑을 한 뒤에 이 w는 “A”를 거쳐서 style, y&#x3D;(ys,yb)<br>로 변형됨. 이때 A는 학습된 affine transform 임. 그리고 이 style들은<br>AdaIN(adaptive instance normalization) opeartion을 control 함.<br><img src="/2020/11/17/GAN%ED%94%84%EB%A1%9C%EC%A0%9D%ED%8A%B8-try/Adain.png" alt="AdaIN"></p>
<p>AdaIN은 style transfer를 할 때 많이 쓰이는 방법으로, 임의의 style transfer를 실시간으로 가능하게 함.<br>여기서 feature map xi는<br>normalized 된 다음에, style로 변환된 두 y로 scaled, biased 됨. (style이 입혀짐)<br>이 과정을 매 layer 마다 반복함. 그리고 이러한 방법은 scale-specific control 을 가능하게 함.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-11-15T17:00:28.000Z" title="2020. 11. 16. 오전 2:00:28">2020-11-16</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:22:12.334Z" title="2022. 4. 5. 오후 3:22:12">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a></span><span class="level-item">4분안에 읽기 (약 634 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/11/16/training-pc/">training_pc</a></h1><div class="content"><h2 id="딥러닝-공부-후기"><a href="#딥러닝-공부-후기" class="headerlink" title="딥러닝 공부 후기"></a>딥러닝 공부 후기</h2><blockquote>
<p>비정형 데이터를 다룰려면 GPU는 필수다.</p>
</blockquote>
<h3 id="Why-GPU"><a href="#Why-GPU" class="headerlink" title="Why GPU ??"></a>Why GPU ??</h3><ol>
<li>CPU보다 더 빠른 병렬 처리 가능</li>
</ol>
<ul>
<li>행렬곱 계산이 CPU보다 훨씬 빠름</li>
</ul>
<ol start="2">
<li>계산 그래프 빌드, 처리 속도가 빠름.</li>
</ol>
<ul>
<li>비정형 데이터 처리엔 GPU가 필수</li>
</ul>
<h3 id="음성-딥러닝-나도-해볼까"><a href="#음성-딥러닝-나도-해볼까" class="headerlink" title="음성 딥러닝, 나도 해볼까?"></a>음성 딥러닝, 나도 해볼까?</h3><p><a target="_blank" rel="noopener" href="https://github.com/topics/vggish">음성 딥러닝</a></p>
<p>음성 딥러닝은 결코 쉽지 않다. 딥러닝계의 보스급.<br>신호처리 배워야 그나마 수월하다.<br>초반 Feature Extraction 경험을 쌓는것을 권장한다.<br>RNN계열의 LSTM으로 시작. 하지만,<br>Attention, Transformer 날코딩 등 논문 구현 경험이 매우 중요하다.<br>Mel Spectrogram을 한다 해도 원리를 잘 알아야 나중에 모델링과 데이터 분해가 쉽다.</p>
<h3 id="딥러닝-입문-방법"><a href="#딥러닝-입문-방법" class="headerlink" title="딥러닝 입문 방법"></a>딥러닝 입문 방법</h3><p>딥러닝 입문 하려면 수학은 필수. 정말 중요.</p>
<p><a target="_blank" rel="noopener" href="https://paperswithcode.com/">논문 구현 시도해보기1</a><br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">논문 구현 시도해보기2</a></p>
<blockquote>
<p>어떤 논문에는 <em>파라미터 하나도 없는</em> 것도 있다.<br>레이어 구조도만 있고 파라미터가 없는 것은 진짜 구현난이도 보스급.</p>
</blockquote>
<h3 id="딥러닝-자격증-취득-후기"><a href="#딥러닝-자격증-취득-후기" class="headerlink" title="딥러닝 자격증 취득 후기"></a>딥러닝 자격증 취득 후기</h3><ol>
<li>문제 유형</li>
</ol>
<ul>
<li><p>Category 1: Basic model</p>
</li>
<li><p>Category 2: Model from learning dataset</p>
</li>
<li><p>Category 3: Image classification<br>Convolutional Neural Network with real-world image dataset</p>
</li>
<li><p>Category 4: Natural language processing (NLP)<br>NLP Text Classification with real-world text dataset</p>
</li>
<li><p>Category 5: Time series, sequences and predictions<br>Sequence Model with real-world numeric dataset</p>
</li>
<li><p>이 시험은 응시자가 TensorFlow 2.x를 통해 모델을 빌드하여 문제를 해결할 수 있는지<br>테스트합니다.</p>
</li>
<li><p>머신러닝(ML) 및 딥러닝의 기본 원칙</p>
</li>
<li><p>TensorFlow 2.x에서 ML 모델 개발하기</p>
</li>
<li><p>심층신경망 및 합성곱 신경망(CNN)을 통한 이미지 인식, 객체 탐지, 텍스트 인식 알고리즘 빌드</p>
</li>
<li><p>컴퓨터가 정보를 ‘보는’ 방식과 플롯 손실 및 정확도 이해할 수 있도록 다른 크기 및 형태의 실제 이미지를 활용하여 합성곱에서 이미지의 경로를 시각화</p>
</li>
<li><p>과적합을 예방하기 위한 확장 및 드롭아웃과 같은 전략 탐색</p>
</li>
<li><p>TensorFlow를 이용하여 자연어 처리 문제를 해결하기 위해 신경망 적용</p>
</li>
</ul>
<blockquote>
<p>Google 공식 페이지 발췌</p>
</blockquote>
<ol start="2">
<li>합격 점수 &#x2F; 규칙</li>
</ol>
<blockquote>
<p>허용된 인터넷 브라우징은 Tensorflow document, 총 100점 만점에 90점 커트라인</p>
</blockquote>
<ul>
<li>난이도는 category 5가 가장 높음</li>
</ul>
<blockquote>
<p>시험 시간 : 5시간 (컴퓨터 딥러닝 훈련시간 포함)</p>
</blockquote>
<p>그럼 20000~!</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-10-25T15:01:21.000Z" title="2020. 10. 26. 오전 12:01:21">2020-10-26</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2021-07-15T10:38:10.000Z" title="2021. 7. 15. 오후 7:38:10">2021-07-15</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/ilsang/">ilsang</a></span><span class="level-item">4분안에 읽기 (약 589 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/10/26/fpost3/">Music Post</a></h1><div class="content"><h2 id="일상을-끄적이다-Mel-Spectrogram-자동-분석을-위한-test-page-입니다"><a href="#일상을-끄적이다-Mel-Spectrogram-자동-분석을-위한-test-page-입니다" class="headerlink" title="일상을 끄적이다 - Mel Spectrogram 자동 분석을 위한 test page 입니다."></a>일상을 끄적이다 - <del>Mel Spectrogram 자동 분석을 위한 test page 입니다.</del></h2><h3 id="M2U-March-Of-Fear"><a href="#M2U-March-Of-Fear" class="headerlink" title="M2U - March Of Fear"></a>M2U - March Of Fear</h3><p>비탄으로 가득 찬 이 도시 안에 떨어지는 Melody,</p>
<p>감정을 연기하는 춤추는 Endless rain…</p>
<p>거짓말로 얼룩진 관계들 속에 웃을 수 있는 거야?</p>
<p>세계를 노래하는 The March of Fear.</p>
<p>We live in the tragedy! 유명한 비극과 같은</p>
<p>잔혹한 세계 속에 우리는 웃음짓고 있어.</p>
<p>이 세계를 비웃는 고결한 수호자들에게</p>
<p>지켜낼 것들은 두려웠던 자신뿐이니까!</p>
<p>숨을 멈춘 사람들 속에서</p>
<p>청명하게 울려퍼지는 Aria…</p>
<p>병든 마음으로 가득찬 이 세계에 폭격을 날려!</p>
<p>지금 웃고 있는 너도 Sociopath, 알잖아?</p>
<p>우리는 이 곳에 생명이 깃든 포성을 던져!</p>
<h3 id="에픽세븐-OST-「Promise」"><a href="#에픽세븐-OST-「Promise」" class="headerlink" title="에픽세븐 OST 「Promise」"></a>에픽세븐 OST 「Promise」</h3><p>깊은 절망 속에 갇혀 쓰러져 가는 나의 두 손을<br>가만히 잡아 준 따스한 너의 온기를 아직<br>난 기억해<br>Now I can hear you<br>눈을 감으면<br>손 끝에서 널 느껴<br>Now I can hear you<br>I can find you<br>이젠 알 수 있어<br>　<br>약속해 Promise I promise 잊지 않을게<br>우리 함께 나눈 약속들을<br>Promise I promise 어둠을 지난<br>N 번째 하늘 아래 이곳에<br>끝이 보이지 않아도 때론 지쳐서 주저 앉아도<br>약속해 희망을 우리 마음에 간절히 모아<br>빛을 향해<br>Now I can hear you<br>눈을 감으면<br>손 끝에서 널 느껴<br>Now I can hear you<br>I can find you<br>이젠 알 수 있어<br>약속해 Promise I promise 잊지 않을게<br>우리 함께 나눈 약속들을<br>Promise I promise 어둠을 지난<br>N 번째 하늘 아래 이곳에  </p>
<p>다시 시작된 시간 다시 걸어가는 길<br>함께하기에 나는 빛날 수 있어<br>멀리 조금씩 보여 따뜻한 파란 빛이<br>우리 마음을 여기에 모아 시작해 한번 더  </p>
<p>약속해 Promise I promise 잊지 않을게<br>우리 함께 나눈 약속들을<br>Promise I promise 어둠을 지난<br>N 번째 하늘 아래  </p>
<p>약속들을</p>
<p>Promise I promise 어둠을 지난<br>N 번째 하늘 아래 이곳에</p>
<blockquote>
<p>개발중인 리듬게임에 쓰기 위한 Mel Spectrogram 분석중 입니다.<br>약간 여운이 있는 노래인거 같습니다.</p>
</blockquote>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-10-24T14:08:30.000Z" title="2020. 10. 24. 오후 11:08:30">2020-10-24</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:21:39.672Z" title="2022. 4. 5. 오후 3:21:39">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a></span><span class="level-item">6분안에 읽기 (약 903 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/10/24/fpost2/">fpost2</a></h1><div class="content"><h2 id="머신러닝과-딥러닝의-차이"><a href="#머신러닝과-딥러닝의-차이" class="headerlink" title="머신러닝과 딥러닝의 차이"></a>머신러닝과 딥러닝의 차이</h2><h3 id="머신러닝"><a href="#머신러닝" class="headerlink" title="머신러닝"></a>머신러닝</h3><ol>
<li>머신러닝은 정형 데이터</li>
</ol>
<ul>
<li>표 형태의 데이터</li>
</ul>
<ol start="2">
<li>딥러닝은 비정형 데이터</li>
</ol>
<ul>
<li>그림, 사진, 오디오 형태의 자연 데이터</li>
</ul>
<h3 id="머신러닝-기초-준비물"><a href="#머신러닝-기초-준비물" class="headerlink" title="머신러닝 기초 준비물"></a>머신러닝 기초 준비물</h3><blockquote>
<p>충분한 용량(RAM 32GB++, SSD 512GB++, i7-10Gen++)의 데스크탑 권장!</p>
</blockquote>
<blockquote>
<p>가장 먼저 <strong>파이썬</strong>, <strong>텐서플로우</strong> 를 설치합니다.</p>
<blockquote>
<p><em>설치 버전 확인!!</em> 매우 중요합니다!</p>
</blockquote>
</blockquote>
<ol>
<li>파이썬</li>
<li>텐서플로우</li>
<li>넘파이 &amp; 싸이킷런</li>
</ol>
<blockquote>
<p>파이썬 버전을 여러개 설치 가능합니다. 이때는 <strong>환경 변수, IDE 경로 셋팅이 중요</strong>합니다.</p>
<blockquote>
<p>윈도우라면 CMD보다는 powershell을 쓰는것이 편합니다.</p>
</blockquote>
</blockquote>
<ol start="4">
<li>제일 쉬운 방법은 아나콘다🛎… 하지만 용량이 큽니다.</li>
</ol>
<blockquote>
<p>써본 결과 리눅스에 도커가 최적 환경입니다⚙️. 추후 포스팅 예정 입니다.📯</p>
</blockquote>
<h3 id="Lets-Burn-the-GPU-🔥🔥🔥-TF2-0-wow"><a href="#Lets-Burn-the-GPU-🔥🔥🔥-TF2-0-wow" class="headerlink" title="Lets Burn the GPU!!🔥🔥🔥(TF2.0 wow!!)"></a>Lets Burn the GPU!!🔥🔥🔥(TF2.0 wow!!)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> sys</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> datetime <span class="keyword">import</span> datetime</span><br><span class="line"></span><br><span class="line"><span class="comment"># tensorflow 실행모드를 확인합니다</span></span><br><span class="line"><span class="built_in">print</span>(tf.executing_eagerly())</span><br><span class="line"></span><br><span class="line">shape = (<span class="built_in">int</span>(<span class="number">10000</span>), <span class="built_in">int</span>(<span class="number">10000</span>))</span><br><span class="line">startTime = datetime.now()</span><br><span class="line"><span class="keyword">with</span> tf.device(<span class="string">&quot;/gpu&quot;</span>):</span><br><span class="line">    random_matrix = tf.random.uniform(shape=shape, minval=<span class="number">0</span>, maxval=<span class="number">1</span>)</span><br><span class="line">    dot_operation = tf.matmul(random_matrix, tf.transpose(random_matrix))</span><br><span class="line">    sum_operation = tf.reduce_sum(dot_operation)</span><br><span class="line"></span><br><span class="line">result = sum_operation</span><br><span class="line"><span class="built_in">print</span>(result)</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span> * <span class="number">2</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;Time taken:&quot;</span>, datetime.now() - startTime)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&quot;\n&quot;</span> * <span class="number">2</span>)</span><br></pre></td></tr></table></figure>

<h3 id="이-모든걸-한번에-해주는-마법의-툴이-있으니-바로-Docker다-Linux-권장"><a href="#이-모든걸-한번에-해주는-마법의-툴이-있으니-바로-Docker다-Linux-권장" class="headerlink" title="이 모든걸 한번에 해주는 마법의 툴이 있으니. 바로 Docker다. (Linux 권장.)"></a>이 모든걸 한번에 해주는 마법의 툴이 있으니. 바로 Docker다. (Linux 권장.)</h3><p>  nano Dockerfile &#x3D;&gt; docker build -t Nyan . &#x3D;&gt; run -d Nyan</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br></pre></td><td class="code"><pre><span class="line">FROM nvidia/cuda:11.2.2-cudnn8-devel-ubuntu20.04</span><br><span class="line">#================================================================================</span><br><span class="line"># Link Cupti</span><br><span class="line">#--------------------------------------------------------------------------------</span><br><span class="line">ENV LD_LIBRARY_PATH $&#123;LD_LIBRARY_PATH&#125;:/usr/local/cuda/extras/CUPTI/lib64</span><br><span class="line"></span><br><span class="line">#================================================================================</span><br><span class="line"># GPU DATA SCIENCE LIBRARY</span><br><span class="line">#--------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">RUN \</span><br><span class="line">    apt-get update &amp;&amp; \</span><br><span class="line">    apt-get install -y libomp-dev libopenblas-base &amp;&amp; \</span><br><span class="line">    # Install pytorch gpu</span><br><span class="line">    # uninstall cpu only packages via conda</span><br><span class="line">    conda remove --force -y pytorch cpuonly &amp;&amp; \</span><br><span class="line">    # https://pytorch.org/get-started/locally/</span><br><span class="line">    conda install cudatoolkit=11.2 -c pytorch -c nvidia &amp;&amp; \</span><br><span class="line">    pip install --no-cache-dir torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html &amp;&amp; \</span><br><span class="line">    # Install cupy: https://cupy.chainer.org/</span><br><span class="line">    pip install --no-cache-dir cupy-cuda112 &amp;&amp; \</span><br><span class="line">    # Install pycuda: https://pypi.org/project/pycuda</span><br><span class="line">    pip install --no-cache-dir pycuda &amp;&amp; \</span><br><span class="line">    # Install gpu utils libs</span><br><span class="line">    pip install --no-cache-dir gpustat py3nvml gputil &amp;&amp; \</span><br><span class="line">    # Install scikit-cuda: https://scikit-cuda.readthedocs.io/en/latest/install.html</span><br><span class="line">    pip install --no-cache-dir scikit-cuda &amp;&amp; \</span><br><span class="line">    # Install tensorflow gpu</span><br><span class="line">    pip uninstall -y tensorflow tensorflow-cpu intel-tensorflow &amp;&amp; \</span><br><span class="line">    pip install --no-cache-dir tensorflow-gpu==2.5.0 &amp;&amp; \</span><br><span class="line">    # Install ONNX GPU Runtime</span><br><span class="line">    pip uninstall -y onnxruntime &amp;&amp; \</span><br><span class="line">    pip install --no-cache-dir onnxruntime-gpu==1.8.0 onnxruntime-training==1.8.0 &amp;&amp; \</span><br><span class="line">    # Install faiss gpu - TODO: to large?</span><br><span class="line">    # conda remove --force -y faiss-cpu &amp;&amp; \</span><br><span class="line">    # conda install -y faiss-gpu -c pytorch &amp;&amp; \</span><br><span class="line">    # Update mxnet to gpu edition</span><br><span class="line">    pip uninstall -y mxnet-mkl &amp;&amp; \</span><br><span class="line">    # cuda111 -&gt; &gt;= 11.1</span><br><span class="line">    pip install --no-cache-dir mxnet-cu112 &amp;&amp; \</span><br><span class="line">    # install jax: https://github.com/google/jax#pip-installation</span><br><span class="line">    pip install --upgrade jax[cuda111] -f https://storage.googleapis.com/jax-releases/jax_releases.html &amp;&amp; \</span><br><span class="line">    # Install pygpu - Required for theano: http://deeplearning.net/software/libgpuarray/</span><br><span class="line">    conda install -y pygpu &amp;&amp; \</span><br><span class="line">    # Install lightgbm</span><br><span class="line">    pip uninstall -y lightgbm &amp;&amp; \</span><br><span class="line">    pip install lightgbm --install-option=--gpu --install-option=&quot;--opencl-include-dir=/usr/local/cuda/include/&quot; --install-option=&quot;--opencl-library=/usr/local/cuda/lib64/libOpenCL.so&quot;  &amp;&amp; \</span><br><span class="line">    # nvidia python ml lib</span><br><span class="line">    pip install --upgrade --force-reinstall nvidia-ml-py3 &amp;&amp; \</span><br><span class="line">    # SpeedTorch: https://github.com/Santosh-Gupta/SpeedTorch</span><br><span class="line">    pip install --no-cache-dir SpeedTorch &amp;&amp; \</span><br><span class="line">    # Ipyexperiments - fix memory leaks</span><br><span class="line">    pip install --no-cache-dir ipyexperiments</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line">cd $RESOURCES_PATH &amp;&amp; \</span><br><span class="line">git clone https://github.com/NVIDIA/apex &amp;&amp; \</span><br><span class="line">cd apex  &amp;&amp; \</span><br><span class="line"># disable printing logging :  &amp;&gt; /dev/null</span><br><span class="line">pip install -v --disable-pip-version-check --no-cache-dir --global-option=&quot;--cpp_ext&quot; --global-option=&quot;--cuda_ext&quot; ./ &amp;&amp; \</span><br><span class="line">rm -rf apex &amp;&amp; \</span><br><span class="line"></span><br><span class="line">ENV TF_FORCE_GPU_ALLOW_GROWTH true</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">RUN apt-get update</span><br><span class="line">RUN apt-get install -y openssh-server language-pack-ko</span><br><span class="line"></span><br><span class="line">RUN rm -rf /var/lib/apt/lists/*</span><br><span class="line"></span><br><span class="line">#===============================================================================</span><br><span class="line"># MISC</span><br><span class="line">#-------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">#Timezone Seoul</span><br><span class="line">ENV TZ=Asia/Seoul</span><br><span class="line">RUN ln -snf /usr/share/zoneinfo/$TZ /etc/localtime &amp;&amp; echo $TZ &gt; /etc/timezone</span><br><span class="line"></span><br><span class="line">ENV LC_ALL=ko_KR.UTF-8</span><br><span class="line">ENV LANG=ko_KR.UTF-8</span><br><span class="line"></span><br><span class="line">#===============================================================================</span><br><span class="line"># user [coder:coder]</span><br><span class="line">#-------------------------------------------------------------------------------</span><br><span class="line">ARG user=coder</span><br><span class="line">ARG group=coder</span><br><span class="line">ARG uid=1000</span><br><span class="line">ARG gid=1000</span><br><span class="line">ARG passwd=coder</span><br><span class="line"></span><br><span class="line">RUN groupadd -g $&#123;gid&#125; $&#123;group&#125; \</span><br><span class="line">  &amp;&amp; useradd -u $&#123;uid&#125; -g $&#123;gid&#125; -m -s /bin/bash $&#123;user&#125; \</span><br><span class="line">  &amp;&amp; echo &quot;$&#123;user&#125;:$&#123;passwd&#125;&quot; | chpasswd \</span><br><span class="line">  &amp;&amp; adduser $&#123;user&#125; sudo \</span><br><span class="line">  &amp;&amp; chown -R $&#123;user&#125; /home/$&#123;user&#125;</span><br><span class="line"></span><br><span class="line">#=================================================================================</span><br><span class="line">#SSH SEtting</span><br><span class="line">#---------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">#RUN mkdir /var/run/sshd</span><br><span class="line">RUN sed -i &quot;s/.*PasswordAuthentication.*/PasswordAuthentication yes/g&quot; /etc/ssh/sshd_config</span><br><span class="line">#SSH login fix. Otherwise user is kicked off after login</span><br><span class="line">RUN sed &#x27;s@session\s*required\s*pam_loginuid.so@session optional pam_loginuid.so@g&#x27; -i /etc/pam.d/sshd</span><br><span class="line"></span><br><span class="line">ENV NOTVISIBLE &quot;in users profile&quot;</span><br><span class="line">RUN echo &quot;export VISIBLE=now&quot; &gt;&gt; /etc/profile</span><br><span class="line"></span><br><span class="line">EXPOSE 22</span><br><span class="line"></span><br><span class="line">#=================================================================================</span><br><span class="line">#shell conf : Set Welcome Message</span><br><span class="line">#---------------------------------------------------------------------------------</span><br><span class="line"></span><br><span class="line">COPY bashrc.sh /etc/bash.bashrc</span><br><span class="line">RUN chmod a+rwx /etc/bash.bashrc</span><br><span class="line"></span><br><span class="line"></span><br></pre></td></tr></table></figure></div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/page/2/">이전</a></div><div class="pagination-next"><a href="/page/4/">다음</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/">1</a></li><li><a class="pagination-link" href="/page/2/">2</a></li><li><a class="pagination-link is-current" href="/page/3/">3</a></li><li><a class="pagination-link" href="/page/4/">4</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="NullSKool"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">NullSKool</p><p class="is-size-6 is-block">NuSkool data blog</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Nyan@null/null</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">포스트</p><a href="/archives"><p class="title">31</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">카테고리</p><a href="/categories"><p class="title">10</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">태그</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/NullSKool" target="_blank" rel="noopener">팔로우</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/NullSKool"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">카테고리</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Competition/"><span class="level-start"><span class="level-item">Competition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Game/"><span class="level-start"><span class="level-item">Game</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/GitPage/"><span class="level-start"><span class="level-item">GitPage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/GitPage/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Study/"><span class="level-start"><span class="level-item">Study</span></span><span class="level-end"><span class="level-item tag">25</span></span></a><ul><li><a class="level is-mobile" href="/categories/Study/Dacon/"><span class="level-start"><span class="level-item">Dacon</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Kaggle-Dacon/"><span class="level-start"><span class="level-item">Kaggle, Dacon</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Papers/"><span class="level-start"><span class="level-item">Papers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ilsang/"><span class="level-start"><span class="level-item">ilsang</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">최근 글</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2023-01-03T00:47:35.000Z">2023-01-03</time></p><p class="title"><a href="/2023/01/03/%EB%B0%B1%EC%97%94%EB%93%9C%EA%B0%9C%EB%B0%9C-01/">백엔드개발_01</a></p><p class="categories"><a href="/categories/Study/">Study</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-16T09:23:41.000Z">2022-10-16</time></p><p class="title"><a href="/2022/10/16/rl-video-summ/">rl-video-summ</a></p><p class="categories"><a href="/categories/Study/">Study</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-10-15T23:28:46.000Z">2022-10-16</time></p><p class="title"><a href="/2022/10/16/%EA%B2%8C%EC%9E%84%EA%B0%9C%EB%B0%9C-%EC%9D%BC%EA%B8%B02/">게임개발-일기2</a></p><p class="categories"><a href="/categories/Game/">Game</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-05T18:49:40.000Z">2022-04-06</time></p><p class="title"><a href="/2022/04/06/Torch-%EC%8A%A4%ED%84%B0%EB%94%94/">Torch_스터디</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-05T07:26:50.000Z">2022-04-05</time></p><p class="title"><a href="/2022/04/05/bbackcheem/">bbackcheem</a></p></div></article></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">링크</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://paperswithcode.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">paper</span></span><span class="level-right"><span class="level-item tag">paperswithcode.com</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">아카이브</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2023/01/"><span class="level-start"><span class="level-item">1월 2023</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/10/"><span class="level-start"><span class="level-item">10월 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">4월 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">9월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">7월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/06/"><span class="level-start"><span class="level-item">6월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/02/"><span class="level-start"><span class="level-item">2월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">1월 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/12/"><span class="level-start"><span class="level-item">12월 2020</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/11/"><span class="level-start"><span class="level-item">11월 2020</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">10월 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">태그</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Audio/"><span class="tag">Audio</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">16</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dacon/"><span class="tag">Dacon</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dev/"><span class="tag">Dev</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HEXO/"><span class="tag">HEXO</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Algebra/"><span class="tag">Linear Algebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">14</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Music-EDA/"><span class="tag">Music EDA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Paper/"><span class="tag">Paper</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Script/"><span class="tag">Script</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TF2/"><span class="tag">TF2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow2/"><span class="tag">Tensorflow2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Try/"><span class="tag">Try</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XR/"><span class="tag">XR</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/blog/"><span class="tag">blog</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/coding/"><span class="tag">coding</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/competition/"><span class="tag">competition</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rules/"><span class="tag">rules</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/unity/"><span class="tag">unity</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="NuSkool" height="28"></a><p class="is-size-7"><span>&copy; 2023 NullSKool</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>