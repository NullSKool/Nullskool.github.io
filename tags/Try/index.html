<!doctype html>
<html lang="ko"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta name="robots" content="noindex"><meta><title>태그: Try - NuSkool</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="NuSkool"><meta name="msapplication-TileImage" content="img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="NuSkool"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="데이터쟁이 블로그입니다."><meta property="og:type" content="blog"><meta property="og:title" content="NuSkool"><meta property="og:url" content="https://nullskool.github.io/"><meta property="og:site_name" content="NuSkool"><meta property="og:description" content="데이터쟁이 블로그입니다."><meta property="og:locale" content="ko_KR"><meta property="og:image" content="https://nullskool.github.io/img/og_image.png"><meta property="article:author" content="NullSKool"><meta property="article:tag" content="Deep Learning, XR, Music"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://NullSKool.github.io"},"headline":"NuSkool","image":["https://nullskool.github.io/img/og_image.png"],"author":{"@type":"Person","name":"NullSKool"},"publisher":{"@type":"Organization","name":"NuSkool","logo":{"@type":"ImageObject","url":"https://nullskool.github.io/img/logo.svg"}},"description":"데이터쟁이 블로그입니다."}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Oxanium:wght@300;400;600&amp;family=Roboto+Mono"><link rel="stylesheet" href="/css/cyberpunk.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-216914004-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-216914004-1');</script><!--!--><!--!--><style>.pace{-webkit-pointer-events:none;pointer-events:none;-webkit-user-select:none;-moz-user-select:none;user-select:none}.pace-inactive{display:none}.pace .pace-progress{background:#3273dc;position:fixed;z-index:2000;top:0;right:100%;width:100%;height:2px}</style><script src="https://cdn.jsdelivr.net/npm/pace-js@1.2.4/pace.min.js"></script><!--!--><!--!--><!-- hexo injector head_end start --><script>
  (function () {
      function switchTab() {
          if (!location.hash) {
            return;
          }
          Array
              .from(document.querySelectorAll('.tab-content'))
              .forEach($tab => {
                  $tab.classList.add('is-hidden');
              });
          Array
              .from(document.querySelectorAll('.tabs li'))
              .forEach($tab => {
                  $tab.classList.remove('is-active');
              });
          const $activeTab = document.querySelector(location.hash);
          if ($activeTab) {
              $activeTab.classList.remove('is-hidden');
          }
          const $tabMenu = document.querySelector(`a[href="${location.hash}"]`);
          if ($tabMenu) {
              $tabMenu.parentElement.classList.add('is-active');
          }
      }
      switchTab();
      window.addEventListener('hashchange', switchTab, false);
  })();
  </script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/rss2.xml" title="NuSkool" type="application/rss+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container navbar-container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/logo.svg" alt="NuSkool" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="검색" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/tags">태그</a></li><li class="is-active"><a href="#" aria-current="page">Try</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-01-30T06:14:16.000Z" title="2021. 1. 30. 오후 3:14:16">2021-01-30</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:21:31.797Z" title="2022. 4. 5. 오후 3:21:31">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/Dacon/">Dacon</a></span><span class="level-item">2분안에 읽기 (약 366 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/30/Dacon%ED%9B%84%EA%B8%B0/">Dacon후기</a></h1><div class="content"><h2 id="저번에-이은-데이콘-도전-후기2"><a href="#저번에-이은-데이콘-도전-후기2" class="headerlink" title="저번에 이은 데이콘 도전 후기2"></a>저번에 이은 데이콘 도전 후기2</h2><p>  순위 발표 순간…<br>  ?!?!?!?!<br>  <img src="/2021/01/30/Dacon%ED%9B%84%EA%B8%B0/dacon01.PNG" alt="순위 발표"></p>
<p>  <img src="/2021/01/30/Dacon%ED%9B%84%EA%B8%B0/dacon02.PNG" alt="자세한 순위"></p>
<p>  1458 팀 중 15위… 와 이거 실화?!</p>
<p>  모델링은 Conv-LSTM</p>
<p>  전처리 방법은 설명력 높은 변수, </p>
<p>  단위면적당 일사량 &#x3D; 산란일사량 + 직접 일사량</p>
<p>  GHI &#x3D; DHI + DNI * \(\cos(\theta))\)  </p>
<p>  하루의 전체 시간 중에서</p>
<p>  해가 뜨고 질 때까지만 계산하는 것이였다.  </p>
<p>  이것이 바로 그 방법들…</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># GHI 계산 방법</span></span><br><span class="line">temp[<span class="string">&#x27;NoSun&#x27;</span>] = np.where((temp[<span class="string">&#x27;DHI&#x27;</span>] &gt; <span class="number">0</span>) | (temp[<span class="string">&#x27;DNI&#x27;</span>] &gt; <span class="number">0</span>), <span class="number">0</span>, <span class="number">1</span>)</span><br><span class="line">  </span><br><span class="line">temp[<span class="string">&#x27;sunny&#x27;</span>] = temp.groupby([<span class="string">&#x27;Day&#x27;</span>, temp.NoSun.cumsum()])[<span class="string">&#x27;NoSun&#x27;</span>].apply(<span class="keyword">lambda</span> x: (x ^ <span class="number">1</span>).cumsum())</span><br><span class="line"></span><br><span class="line">temp[<span class="string">&#x27;long&#x27;</span>] = temp[<span class="string">&#x27;sunny&#x27;</span>].cummax()</span><br><span class="line"></span><br><span class="line">temp[<span class="string">&#x27;angle&#x27;</span>] = ((temp[<span class="string">&#x27;sunny&#x27;</span>] / temp[<span class="string">&#x27;long&#x27;</span>]) * <span class="number">180</span>) - <span class="number">90</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">temp[<span class="string">&#x27;GHI&#x27;</span>] = temp[<span class="string">&#x27;DHI&#x27;</span>] + temp[<span class="string">&#x27;DNI&#x27;</span>] * temp[<span class="string">&#x27;angle&#x27;</span>].apply(<span class="keyword">lambda</span> x: np.cos(np.pi * (x / <span class="number">180</span>)))</span><br><span class="line"></span><br><span class="line"><span class="comment"># DataSet windowing 하는 방법</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">windowed_dataset</span>(<span class="params">x, y, window_size, batch_size, shuffle, shuffle_size</span>):</span><br><span class="line">  ds_x = tf.data.Dataset.from_tensor_slices(x)</span><br><span class="line">  ds_x = ds_x.window(window_size, shift = <span class="number">1</span>, stride = <span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">  ds_x = ds_x.flat_map(<span class="keyword">lambda</span> x: x.batch(window_size))</span><br><span class="line">  </span><br><span class="line">  ds_y = tf.data.Dataset.from_tensor_slices(y)</span><br><span class="line">  ds_y = ds_y.window(window_size, shift = <span class="number">1</span>, stride = <span class="number">1</span>, drop_remainder=<span class="literal">True</span>)</span><br><span class="line">  ds_y = ds_y.flat_map(<span class="keyword">lambda</span> x: x.batch(window_size))</span><br><span class="line">  </span><br><span class="line">  ds = tf.data.Dataset.<span class="built_in">zip</span>((ds_x, ds_y))</span><br><span class="line">  <span class="keyword">if</span> shuffle:</span><br><span class="line">      ds = ds.shuffle(shuffle_size)</span><br><span class="line">  <span class="keyword">return</span> ds.batch(batch_size).prefetch(<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">window_data_pred</span>(<span class="params">data, window_size, batch_size</span>):</span><br><span class="line">    ds = tf.data.Dataset.from_tensor_slices(data)</span><br><span class="line">    ds = ds.window(window_size, shift = <span class="number">1</span>, stride = <span class="number">1</span>) <span class="comment">#, drop_remainder=True) # stride = 1</span></span><br><span class="line">    ds = ds.flat_map(<span class="keyword">lambda</span> x: x.batch(window_size))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> ds.padded_batch(batch_size, padded_shapes=(<span class="literal">None</span>, <span class="number">7</span>)).prefetch(<span class="number">1</span>) <span class="comment"># 7은 Test Set의 특징 개수</span></span><br></pre></td></tr></table></figure>
<h3 id="Test-dataset을-drop-remainder-x3D-True-하면-안되는-이유"><a href="#Test-dataset을-drop-remainder-x3D-True-하면-안되는-이유" class="headerlink" title="Test dataset을 drop_remainder&#x3D;True 하면 안되는 이유?"></a>Test dataset을 drop_remainder&#x3D;True 하면 안되는 이유?</h3><p>  Test Set의 정보가 sequence length만큼 없어짐.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-01-03T04:05:29.000Z" title="2021. 1. 3. 오후 1:05:29">2021-01-03</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-04-05T06:20:21.669Z" title="2022. 4. 5. 오후 3:20:21">2022-04-05</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a></span><span class="level-item">5분안에 읽기 (약 677 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/03/%EC%86%8C%EC%86%8C%ED%95%9C-%EC%97%B0%EA%B5%AC%EC%95%84%EB%8B%8C-%EC%97%B0%EA%B5%AC/">소소한 연구아닌 연구</a></h1><div class="content"><h2 id="넘사벽-난이도인-트랜스포머-모델링"><a href="#넘사벽-난이도인-트랜스포머-모델링" class="headerlink" title="넘사벽 난이도인 트랜스포머 모델링"></a>넘사벽 난이도인 트랜스포머 모델링</h2><p>  시계열 데이터를 병렬 처리한다는 점에서는 가장 좋지만<br>  그만큼 모델링 하기가 까다롭다.</p>
<p>  model input : (Batch, Sequence, feature_num)</p>
<p>  Transformer는 input &#x2F; output을 잘못 설계하다간 sequence 정보가 날아갈 수도 있고<br>  그냥 데이터 자체가 8:45 가 될수가 있다.</p>
<p>  입력 데이터를 Seqneuce로 Packing 해주어야 학습이 가능한 데이터가 된다.</p>
<p>  Sequence Packing 방법은 파이썬 문법으로 비교적 쉽게 되지만…</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">df_train = train.values</span><br><span class="line">train_seq = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(seq_len, <span class="built_in">len</span>(df_train)+<span class="number">1</span>):</span><br><span class="line">  train_seq.append(df_train[i - seq_len: i])</span><br><span class="line">train_seq = np.array(train_seq)</span><br></pre></td></tr></table></figure>

<p>  Sequence unpacking 은 numpy 연산을 써야 비교적 쉬움..<br>  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">out = np.vstack(r <span class="keyword">for</span> r <span class="keyword">in</span> train_seq)</span><br><span class="line">out = out.unique(out, axis=<span class="number">0</span>)</span><br></pre></td></tr></table></figure></p>
<p>  <img src="/2021/01/03/%EC%86%8C%EC%86%8C%ED%95%9C-%EC%97%B0%EA%B5%AC%EC%95%84%EB%8B%8C-%EC%97%B0%EA%B5%AC/%ED%8F%AC%ED%8A%B8%ED%8F%B4%EB%A6%AC%EC%98%A41.PNG" alt="packing &amp; unpacking"></p>
<p>  <img src="/2021/01/03/%EC%86%8C%EC%86%8C%ED%95%9C-%EC%97%B0%EA%B5%AC%EC%95%84%EB%8B%8C-%EC%97%B0%EA%B5%AC/%ED%8F%AC%ED%8A%B8%ED%8F%B4%EB%A6%AC%EC%98%A42.PNG" alt="unpacking2"></p>
<h3 id="다변량-회귀에서-얻은-교훈-1"><a href="#다변량-회귀에서-얻은-교훈-1" class="headerlink" title="다변량 회귀에서 얻은 교훈 1"></a>다변량 회귀에서 얻은 교훈 1</h3><p>  입력 데이터를 받아서 Time Embedding…</p>
<p>  시간별 Positional Encoding 방법을 소개하지.</p>
<p>  y &#x3D; wx + b concat sin(wx+b)</p>
<p>  선형의 시간 특징과 주기성의 특징에다 sin을 적용한 특징임.</p>
  <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Time2Vector</span>(<span class="title class_ inherited__">Layer</span>):</span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, seq_len, **kwargs</span>):</span><br><span class="line">      <span class="built_in">super</span>(Time2Vector, self).__init__()</span><br><span class="line">      self.seq_len = seq_len</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">build</span>(<span class="params">self, input_shape</span>):</span><br><span class="line">      <span class="string">&#x27;&#x27;&#x27;shape (batch, seq_len) 형태로 가중치와 Bias 초기화 &#x27;&#x27;&#x27;</span></span><br><span class="line">      self.weights_linear = self.add_weight(name=<span class="string">&#x27;weight_linear&#x27;</span>,</span><br><span class="line">                                  shape=(<span class="built_in">int</span>(self.seq_len),),</span><br><span class="line">                                  initializer=<span class="string">&#x27;uniform&#x27;</span>,</span><br><span class="line">                                  trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">      self.bias_linear = self.add_weight(name=<span class="string">&#x27;bias_linear&#x27;</span>,</span><br><span class="line">                                  shape=(<span class="built_in">int</span>(self.seq_len),),</span><br><span class="line">                                  initializer=<span class="string">&#x27;uniform&#x27;</span>,</span><br><span class="line">                                  trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">      self.weights_periodic = self.add_weight(name=<span class="string">&#x27;weight_periodic&#x27;</span>,</span><br><span class="line">                                  shape=(<span class="built_in">int</span>(self.seq_len),),</span><br><span class="line">                                  initializer=<span class="string">&#x27;uniform&#x27;</span>,</span><br><span class="line">                                  trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">      self.bias_periodic = self.add_weight(name=<span class="string">&#x27;bias_periodic&#x27;</span>,</span><br><span class="line">                                  shape=(<span class="built_in">int</span>(self.seq_len),),</span><br><span class="line">                                  initializer=<span class="string">&#x27;uniform&#x27;</span>,</span><br><span class="line">                                  trainable=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">  <span class="keyword">def</span> <span class="title function_">call</span>(<span class="params">self, x</span>):</span><br><span class="line">      <span class="string">&#x27;&#x27;&#x27;주기성, 선형 시간별 특징을 계산&#x27;&#x27;&#x27;</span></span><br><span class="line">      x = tf.math.reduce_mean(x[:,:,:], axis=-<span class="number">1</span>) <span class="comment"># 입력 Feature 차원 슬라이싱</span></span><br><span class="line">      time_linear = self.weights_linear * x + self.bias_linear <span class="comment"># 선형 시간 특징</span></span><br><span class="line">      time_linear = tf.expand_dims(time_linear, axis=-<span class="number">1</span>) <span class="comment"># 차원 추가 (batch, seq_len, 1)</span></span><br><span class="line"></span><br><span class="line">      time_periodic = tf.math.sin(tf.multiply(x, self.weights_periodic) + self.bias_periodic)</span><br><span class="line">      time_periodic = tf.expand_dims(time_periodic, axis=-<span class="number">1</span>) <span class="comment"># 차원 추가 (batch, seq_len, 1)</span></span><br><span class="line">      <span class="keyword">return</span> tf.concat([time_linear, time_periodic], axis=-<span class="number">1</span>) <span class="comment"># shape = (batch, seq_len, 2)</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>
<h3 id="트랜스포머의-특징"><a href="#트랜스포머의-특징" class="headerlink" title="트랜스포머의 특징"></a>트랜스포머의 특징</h3><p>  시계열 데이터 분류, 회귀 문제에서는<br>  Decoder가 빠져있는 Self Attention을 사용한다.  (Fine Tunning)</p>
<p>  Decoder는 챗봇이나 Auto-Encoder같은 Encoder-Decoder 구조에 사용되는 경향이 있다.</p>
<p>  참고 논문 : <a target="_blank" rel="noopener" href="https://openreview.net/forum?id=lE1AB4stmX">https://openreview.net/forum?id=lE1AB4stmX</a></p>
<p>  논문에서는 n_layer_num, padding_mask 를 쓰는 특징이 있다. 이 파라미터까지 쓸 수 있으면 좋겠지만<br>  GPU 메모리가 8기가밖에 안되서 논문 파라미터보다는 작게 설정을 해야 원활이 가능하다.<br>  그리고 dataset을 window 하면 GPU RAM 사용량을 더 낮출 수 있다.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2021-01-02T12:56:29.000Z" title="2021. 1. 2. 오후 9:56:29">2021-01-02</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-07-24T11:09:12.206Z" title="2022. 7. 24. 오후 8:09:12">2022-07-24</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/Kaggle-Dacon/">Kaggle, Dacon</a></span><span class="level-item">4분안에 읽기 (약 612 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2021/01/02/%EC%B9%98%EC%97%B4%ED%95%9C-%EB%8D%B0%EC%9D%B4%EC%BD%98%ED%9B%84%EA%B8%B0/">치열한-데이콘후기</a></h1><div class="content"><h2 id="데이콘-최근-대회-후기-데이콘-어나더-버전"><a href="#데이콘-최근-대회-후기-데이콘-어나더-버전" class="headerlink" title="데이콘 최근 대회 후기 - 데이콘 어나더 버전"></a>데이콘 최근 대회 후기 - 데이콘 어나더 버전</h2><p>  흥미롭지만 quantile loss… 복잡하지만 풀이법은 있다.<br>  그냥 quantile 별로 돌리지 말고 1.0에 대한 값을 예측한 뒤 0.5 ~ 1.0 범위로 하면 끝;;<br>  <del>loss function 수식구현은 쉽지만 loss를 줄이는 방법이 관건이다.</del><br>  <del>진짜 4.1에서 줄어들지 않는 loss… 과연 어떻게 하면 줄일수 있을까…</del></p>
<h3 id="다변량-회귀-왜-이렇게-어려울까요-데이콘-대회에서-얻은-엄청난-교훈"><a href="#다변량-회귀-왜-이렇게-어려울까요-데이콘-대회에서-얻은-엄청난-교훈" class="headerlink" title="다변량 회귀 왜 이렇게 어려울까요? - 데이콘 대회에서 얻은 엄청난 교훈"></a>다변량 회귀 왜 이렇게 어려울까요? - 데이콘 대회에서 얻은 엄청난 교훈</h3><p>  <del>loss 계산할때 다른 target 값과 x_train값이 아닌</del></p>
<p>  <del>다른 Element 끼리 계산되어서 오히려 loss가 폭증하기도 한다 이렇게 하면 8:45 된다.</del></p>
<p>  Wandb로 시각화 안했으면 큰일났었을듯 싶었다. </p>
<p>  Loss 시각화 툴로 보니 초반에서 수렴하지 않는 문제나 아예 u자로 불규칙적으로 튀는 현상도 발생….</p>
<p>  <img src="/2021/01/02/%EC%B9%98%EC%97%B4%ED%95%9C-%EB%8D%B0%EC%9D%B4%EC%BD%98%ED%9B%84%EA%B8%B0/%EC%8B%A0%EA%B8%B0%ED%95%9C%EA%B7%B8%EB%9E%98%ED%94%84.PNG" alt="loss가 줄어드는 것처럼 보이지만 실제는 ..."></p>
<p>  <del>분명 window dataset으로 부하분산을 하면 데이터 처리가 수월할 것 같지만…이렇게 되면 끗;;;</del></p>
<p>  <del>채점을 해보니 극악의 Loss가 나오기도 한다. 에측 label과 train test의 shape을 확인 또 확인..</del></p>
<p>  떄에는 window_size, buffer size를 잘 조절해야 한다.</p>
<p>  window_size를 너무 낮추면 자칫하면 GPU 사용률은 한자리에 머물고 시간은 오래 걸린다. </p>
<p>  하지만 GPU RAM 사용량은 줄어드는 이점은 있다.</p>
<p>  window dataset을 하다보면 배치 크기가 안 맞아서 예측이 안될때가 있는데 이럴땐…<br>  <img src="/2021/01/02/%EC%B9%98%EC%97%B4%ED%95%9C-%EB%8D%B0%EC%9D%B4%EC%BD%98%ED%9B%84%EA%B8%B0/%ED%9D%90%EC%9D%B5.PNG" alt="배치 크기가 안맞을 떄는 이렇게 padding을 쓴다."></p>
<p>  Shuffle Buffer size 조절은 필수, batch Size에 주의하여 조절한다.<br>  그렇지 않으면(BATCH SIZE가 굉장히 높다면)<br>  <figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">WARNING:tensorflow:5 out of the last 5 calls to &lt;function Model.make_predict_function.&lt;locals&gt;.predict_function at 0x7f2570221d30&gt; triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details. </span><br></pre></td></tr></table></figure></p>
<p>  이런 경고가 나온다.. -&gt; batch size를 반드시 조절하거나 batch padding…</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-12-22T15:13:20.000Z" title="2020. 12. 23. 오전 12:13:20">2020-12-23</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-07-24T10:57:44.143Z" title="2022. 7. 24. 오후 7:57:44">2022-07-24</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/Kaggle-Dacon/">Kaggle, Dacon</a></span><span class="level-item">3분안에 읽기 (약 454 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/23/%EC%96%B4%EB%82%98%EB%8D%94Dacon%EB%8F%84%EC%A0%84%EA%B8%B0-2/">어나더Dacon도전기_2</a></h1><div class="content"><h2 id="데이콘-또다른-대회-후기-데이콘-어나더🌠🌠"><a href="#데이콘-또다른-대회-후기-데이콘-어나더🌠🌠" class="headerlink" title="데이콘 또다른 대회 후기 - 데이콘 어나더🌠🌠"></a>데이콘 또다른 대회 후기 - 데이콘 어나더🌠🌠</h2><p>  <del>Regression, CNN, LSTM 모델의 iteration epoch 횟수를<br>  너무 많이 늘리면 Overfitting이 날 수 있으니 LR 스케줄러 등 다양한 방법을 시도해봐야 한다.</del></p>
<h3 id="CNN-LSTM-다변량-회귀-모델링-후기🌠"><a href="#CNN-LSTM-다변량-회귀-모델링-후기🌠" class="headerlink" title="CNN-LSTM 다변량 회귀 모델링 후기🌠"></a>CNN-LSTM 다변량 회귀 모델링 후기🌠</h3><p>  처음에는 왜 이렇게 loss가 줄지 않는지 🎚 의문이 들었다.🌠<br>  quantile 로 계산해야 할 경우는 quantile 1.0을 구한뒤에<br>  0.1 ~ 1.0 을 적용하면 된다.  </p>
<p>  <img src="/2020/12/23/%EC%96%B4%EB%82%98%EB%8D%94Dacon%EB%8F%84%EC%A0%84%EA%B8%B0-2/Multi_var_reg.PNG" alt="loss가 전혀 줄지 않음"></p>
<p>  이렇게 되면 8:45 가 되버림 : 잘못된 예시<br>  quantile 적용의 안좋은 예시.</p>
<p>  시계열 문제는 시간, 구간당 평균이나 여러 통계적 변수를 만들어야 점수가 더 잘나오는 특징이 있다.⏩  </p>
<p>  그걸 해결하기 위해서는 prophet 사용하면 그나마 해결이 잘 된다.</p>
<p>  <a target="_blank" rel="noopener" href="https://github.com/sachinruk/KerasQuantileModel/blob/master/Keras%20Quantile%20Model.ipynb">참고문서1</a></p>
<p>  <del>역시나 예측이 맞았다. Epoch을 약간(?) 겁나게 늘리고 optimizer나 다른 학습율 스케줄러, sgd에 decay, momentum 을 주어야 하나보다.</del></p>
<p>  <del>다변량 회귀이기 때문에 validation loss 계산이 약간 신중해야 정확한 loss값이 계산이 가능하다.</del></p>
<p>  <del>test dataset에 element-wise 방식으로 계산되는거라 test dataset shape 그대로 predict가 출력된다.</del></p>
<p>  <del>Reshape, Squeeze 를 써서 shape을 맞춰주어야 한다…</del><br>  element-wise 하게 계산되면 GG, window 된 shape을 확인 또 확인 해야함.  </p>
<p>  Quantile Regression 문제는 그냥 Regression에 Quantile별로 값을 추출해야 하는 약간의(?) 난제가 존재한다.</p>
<p>  <del>Pytorch는 🐍 하지만 어떤 면에서는 TF2.x 보다 더 까다로운 것 같다. 여러 프레임워크를 많이 써보자..</del></p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-12-08T15:16:14.000Z" title="2020. 12. 9. 오전 12:16:14">2020-12-09</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-07-26T08:53:11.061Z" title="2022. 7. 26. 오후 5:53:11">2022-07-26</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Competition/">Competition</a></span><span class="level-item">2분안에 읽기 (약 251 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/09/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C-%ED%9B%84%EA%B8%B0/">인공지능 경진대회 후기</a></h1><div class="content"><h2 id="인공지능-문제해결-경진대회-참가후기-2020-2021-🔔"><a href="#인공지능-문제해결-경진대회-참가후기-2020-2021-🔔" class="headerlink" title="인공지능 문제해결 경진대회 참가후기 2020, 2021 🔔"></a>인공지능 문제해결 경진대회 참가후기 2020, 2021 🔔</h2><p>  정말 치열했던 경진대회였다. </p>
<p>  처음에는 이미지 멀티라벨 다중 분류 문제가 나왔었고  </p>
<p>  그 이후 본선대회에서는 NLP, OCR, GAN 등 여러 도메인 문제가 출현했었다  </p>
<p>  베이스라인 코드 그런건 사실상 없ㅋ음ㅋ..🔐</p>
<p>  그냥 데이터를 말 그대로 해체 분석을 했어야 했다.</p>
<p>  아무리 Data Clensing을 해도 그대로인 loss와 score… 8:45🕛</p>
<p>  결국 아예 리모델링, 데이터 Cleanize 한 뒤에 학습을 다시 돌렸다.</p>
<p>  천신만고 끝에…</p>
<p>  <img src="/2020/12/09/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C-%ED%9B%84%EA%B8%B0/2222.PNG" alt="최종순위...ㄷㄷㄷ"></p>
<p>  <img src="/2020/12/09/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C-%ED%9B%84%EA%B8%B0/3333.PNG" alt="최종순위 ㅎㄷㄷ"></p>
<p>  <img src="/2020/12/09/%EC%9D%B8%EA%B3%B5%EC%A7%80%EB%8A%A5-%EA%B2%BD%EC%A7%84%EB%8C%80%ED%9A%8C-%ED%9B%84%EA%B8%B0/4444.PNG" alt="최종순위 ㄷㄷㄷ;;"><br>    참고로 팀명은 <del>풍선띄우기</del> ;;</p>
<p>  최종 명단에 발표되기까지 엄청난 긴장감이…🌡📈</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item"><time dateTime="2020-12-06T12:48:20.000Z" title="2020. 12. 6. 오후 9:48:20">2020-12-06</time>&nbsp;게시 됨</span><span class="level-item"><time dateTime="2022-10-16T02:07:54.140Z" title="2022. 10. 16. 오전 11:07:54">2022-10-16</time>&nbsp;업데이트 됨</span><span class="level-item"><a class="link-muted" href="/categories/Study/">Study</a><span> / </span><a class="link-muted" href="/categories/Study/Kaggle-Dacon/">Kaggle, Dacon</a></span><span class="level-item">2분안에 읽기 (약 331 단어)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/2020/12/06/Dacon%EB%8F%84%EC%A0%84%EA%B8%B0/">Dacon도전기</a></h1><div class="content"><h2 id="데이콘-도전-후기"><a href="#데이콘-도전-후기" class="headerlink" title="데이콘 도전 후기"></a>데이콘 도전 후기</h2><p>  흥미롭지만 쉽지는 않다.<br>  말 그대로 새로운 파생변수, 모델을 많이 만들면 점수가 오르긴 한다.</p>
<p>  <a target="_blank" rel="noopener" href="https://dacon.io/competitions/open/235597/leaderboard/">데이콘_연습문제</a></p>
<p>  연습용이긴 한데 BERT모델 폭격으로 <del>양민학살</del> 이 벌써부터 시작되었…ㅎㄷㄷ</p>
<p>  버트모델 안쓰고도 순위 올릴수는 있다. </p>
<p>  지금부터 그 방법을 소개합니다.</p>
<h3 id="데이콘-순위를-올릴수-있는-방법-창의적인-modeling-K-cross-Validation-parameter-searching"><a href="#데이콘-순위를-올릴수-있는-방법-창의적인-modeling-K-cross-Validation-parameter-searching" class="headerlink" title="데이콘 순위를 올릴수 있는 방법 - 창의적인 modeling, K-cross Validation, parameter searching"></a>데이콘 순위를 올릴수 있는 방법 - 창의적인 modeling, K-cross Validation, parameter searching</h3><p>  <img src="/2020/12/06/Dacon%EB%8F%84%EC%A0%84%EA%B8%B0/vdcnn_1.PNG" alt="이것이 바로 VDCNN">  </p>
<p>  VDCNN은 GPU가 잘 버텨주면<br>  0.86까지는 마구마구 올릴수 있음.  </p>
<p>  이것이 바로 VDCNN이당!<br>  <a target="_blank" rel="noopener" href="https://github.com/NullSKool/VDCNN_kor"><img src="/2020/12/06/Dacon%EB%8F%84%EC%A0%84%EA%B8%B0/vdcnn_5.PNG" alt="VDCNN code"></a></p>
<p>  <img src="/2020/12/06/Dacon%EB%8F%84%EC%A0%84%EA%B8%B0/vdcnn_9.PNG" alt="VDCNN 학습장면"></p>
<p>  학습 모델을 그림으로 보기</p>
<p>  <img src="/2020/12/06/Dacon%EB%8F%84%EC%A0%84%EA%B8%B0/output_36_0.png" alt="VDCNN 그림1"></p>
<p>  <img src="/2020/12/06/Dacon%EB%8F%84%EC%A0%84%EA%B8%B0/Dacon01.PNG" alt="데이콘 결과"><br>  여기에 여러 가지 모델 Ensemble 해보면 0.88은 가능해보일 것 같네요.</p>
<blockquote>
<p>추가로 모델 Ensemble 을 시도<br>  <img src="/2020/12/06/Dacon%EB%8F%84%EC%A0%84%EA%B8%B0/output_43_0.png" alt="추가했던 모델1"><br>  <img src="/2020/12/06/Dacon%EB%8F%84%EC%A0%84%EA%B8%B0/output_50_0.png" alt="추가했던 모델2"><br>  <img src="/2020/12/06/Dacon%EB%8F%84%EC%A0%84%EA%B8%B0/output_57_0.png" alt="추가했던 모델3"></p>
</blockquote>
<blockquote>
<p>추가적으로 트랜스포머 모델링..(2020-12-09 추가…)<br>  <a target="_blank" rel="noopener" href="https://github.com/NullSKool/VDCNN_kor/blob/master/TF2_kor_2.0.ipynb">Transformer</a></p>
</blockquote>
</div></article></div></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar" src="/img/avatar.png" alt="NullSKool"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">NullSKool</p><p class="is-size-6 is-block">NuSkool data blog</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Nyan@null/null</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">포스트</p><a href="/archives"><p class="title">29</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">카테고리</p><a href="/categories"><p class="title">10</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">태그</p><a href="/tags"><p class="title">21</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/NullSKool" target="_blank" rel="noopener">팔로우</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/NullSKool"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Facebook" href="https://facebook.com"><i class="fab fa-facebook"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Dribbble" href="https://dribbble.com"><i class="fab fa-dribbble"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">카테고리</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/Competition/"><span class="level-start"><span class="level-item">Competition</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Game/"><span class="level-start"><span class="level-item">Game</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/categories/GitPage/"><span class="level-start"><span class="level-item">GitPage</span></span><span class="level-end"><span class="level-item tag">1</span></span></a><ul><li><a class="level is-mobile" href="/categories/GitPage/Hexo/"><span class="level-start"><span class="level-item">Hexo</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/Study/"><span class="level-start"><span class="level-item">Study</span></span><span class="level-end"><span class="level-item tag">23</span></span></a><ul><li><a class="level is-mobile" href="/categories/Study/Dacon/"><span class="level-start"><span class="level-item">Dacon</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Deep-Learning/"><span class="level-start"><span class="level-item">Deep Learning</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Kaggle-Dacon/"><span class="level-start"><span class="level-item">Kaggle, Dacon</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/categories/Study/Papers/"><span class="level-start"><span class="level-item">Papers</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/ilsang/"><span class="level-start"><span class="level-item">ilsang</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li></ul></div></div></div><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">최근 글</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-05T18:49:40.000Z">2022-04-06</time></p><p class="title"><a href="/2022/04/06/Torch-%EC%8A%A4%ED%84%B0%EB%94%94/">Torch_스터디</a></p><p class="categories"><a href="/categories/Study/">Study</a> / <a href="/categories/Study/Deep-Learning/">Deep Learning</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-04-05T07:26:50.000Z">2022-04-05</time></p><p class="title"><a href="/2022/04/05/bbackcheem/">bbackcheem</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-09-06T05:54:41.000Z">2021-09-06</time></p><p class="title"><a href="/2021/09/06/Multi-GPU/">Multi-GPU</a></p><p class="categories"><a href="/categories/Study/">Study</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-07-15T10:43:57.000Z">2021-07-15</time></p><p class="title"><a href="/2021/07/15/%EB%85%BC%EB%AC%B8-%EB%A6%AC%EB%B7%B0/">논문 리뷰</a></p><p class="categories"><a href="/categories/Study/">Study</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2021-06-19T23:28:46.000Z">2021-06-20</time></p><p class="title"><a href="/2021/06/20/%EA%B2%8C%EC%9E%84%EA%B0%9C%EB%B0%9C-%EC%9D%BC%EA%B8%B02/">게임개발-일기2</a></p><p class="categories"><a href="/categories/Game/">Game</a></p></div></article></div></div><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="links"><div class="card-content"><div class="menu"><h3 class="menu-label">링크</h3><ul class="menu-list"><li><a class="level is-mobile" href="https://paperswithcode.com" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">paper</span></span><span class="level-right"><span class="level-item tag">paperswithcode.com</span></span></a></li><li><a class="level is-mobile" href="https://bulma.io" target="_blank" rel="noopener"><span class="level-left"><span class="level-item">Bulma</span></span><span class="level-right"><span class="level-item tag">bulma.io</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">아카이브</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/04/"><span class="level-start"><span class="level-item">4월 2022</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/09/"><span class="level-start"><span class="level-item">9월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/07/"><span class="level-start"><span class="level-item">7월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/06/"><span class="level-start"><span class="level-item">6월 2021</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/02/"><span class="level-start"><span class="level-item">2월 2021</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2021/01/"><span class="level-start"><span class="level-item">1월 2021</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/12/"><span class="level-start"><span class="level-item">12월 2020</span></span><span class="level-end"><span class="level-item tag">6</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/11/"><span class="level-start"><span class="level-item">11월 2020</span></span><span class="level-end"><span class="level-item tag">10</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/10/"><span class="level-start"><span class="level-item">10월 2020</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">태그</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Audio/"><span class="tag">Audio</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/DL/"><span class="tag">DL</span><span class="tag">15</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dacon/"><span class="tag">Dacon</span><span class="tag">4</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Dev/"><span class="tag">Dev</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/HEXO/"><span class="tag">HEXO</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Linear-Algebra/"><span class="tag">Linear Algebra</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/ML/"><span class="tag">ML</span><span class="tag">13</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Music-EDA/"><span class="tag">Music EDA</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Paper/"><span class="tag">Paper</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Script/"><span class="tag">Script</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/TF2/"><span class="tag">TF2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Tensorflow2/"><span class="tag">Tensorflow2</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Try/"><span class="tag">Try</span><span class="tag">6</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Unity/"><span class="tag">Unity</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/XR/"><span class="tag">XR</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/blog/"><span class="tag">blog</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/coding/"><span class="tag">coding</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/competition/"><span class="tag">competition</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rules/"><span class="tag">rules</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/unity/"><span class="tag">unity</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/logo.svg" alt="NuSkool" height="28"></a><p class="is-size-7"><span>&copy; 2022 NullSKool</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("ko");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="맨 위로" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "이 웹 사이트는 귀하의 경험을 향상시키기 위해 Cookie를 사용합니다.",
          dismiss: "무시",
          allow: "허용",
          deny: "거부",
          link: "더 알아보기",
          policy: "Cookie 정책",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.10.0/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.8.1/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.9/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="입력 하세요..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"입력 하세요...","untitled":"(제목 없음)","posts":"포스트","pages":"페이지","categories":"카테고리","tags":"태그"});
        });</script></body></html>